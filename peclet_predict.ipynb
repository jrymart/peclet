{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dgxIi-LYi34h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9205fd-07dd-4e32-b09f-0e25fb3aba79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torchdata-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torch\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2A2jdWkg5q2B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQshN0GiDP_V",
        "outputId": "2c4c012f-6f27-456d-82e8-3c8b533c072c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database = \"/content/drive/MyDrive/peclet_batch_one.db\"\n",
        "files = \"/content/drive/MyDrive/peclet_batch_one\""
      ],
      "metadata": {
        "id": "jD7mS2Uk5upf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connection = sqlite3.connect(database)\n",
        "cursor = connection.cursor()\n",
        "cursor.execute(\"SELECT DISTINCT \\\"model_param.seed\\\" FROM model_run_params\")\n",
        "seeds = [r[0] for r in cursor.fetchall()]\n",
        "split = int((len(seeds)/10)*8)\n",
        "train_seeds = seeds[:split]\n",
        "test_seeds = seeds[split:]\n",
        "train_filter = \"WHERE \\\"model_param.seed\\\" in %s\" % str(tuple(train_seeds))\n",
        "test_filter = \"WHERE \\\"model_param.seed\\\" in %s\" % str(tuple(test_seeds))"
      ],
      "metadata": {
        "id": "M180dKPm6LqQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_query = \"SELECT \\\"model_param.streampower.k\\\"/ \\\"model_param.diffuser.D\\\" FROM model_run_params\""
      ],
      "metadata": {
        "id": "D7jzlq9Z-DWg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_runs(database, filter_query = \"\"):\n",
        "    connection = sqlite3.connect(database)\n",
        "    cursor = connection.cursor()\n",
        "    run_query = f\"SELECT model_run_id FROM model_run_params {filter_query}\"\n",
        "    cursor.execute(run_query)\n",
        "    return [r[0] for r in cursor.fetchall()]\n",
        "\n",
        "class LandlabBatchdataset(Dataset):\n",
        "    def __init__(self, database, dataset_dir, label_query, filter_query=None):\n",
        "        self.img_db = database\n",
        "        self.dataset_directory = dataset_dir\n",
        "        self.connection = sqlite3.connect(database)\n",
        "        self.cursor = connection.cursor()\n",
        "        self.label_query = label_query\n",
        "        if filter_query is not None:\n",
        "            self.filter_query = filter_query\n",
        "        else:\n",
        "            self.filter_query = \"\"\n",
        "        self.runs = get_runs(database, filter_query)\n",
        "        self.transform = ToTensor()\n",
        "        self.target_transform = ToTensor()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.runs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        run_name = self.runs[idx]\n",
        "        data_path = os.path.join(self.dataset_directory, f\"{run_name}.npz\")\n",
        "        label_query = f\"{self.label_query} WHERE model_run_id = \\\"{run_name}\\\"\"\n",
        "        self.cursor.execute(label_query)\n",
        "        label = self.cursor.fetchone()\n",
        "        data_array = np.load(data_path)[run_name]\n",
        "        data_array = data_array.astype(np.float32)\n",
        "        data_array = self.transform(data_array)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        return data_array, label"
      ],
      "metadata": {
        "id": "obiDVUW_8J6F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PecletPredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 20, kernel_size=(5,5))\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2), stride=(2,2))\n",
        "    self.conv2 = nn.Conv2d(20, 50, (5,5))\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2), stride=(2,2))\n",
        "    self.fc1 = nn.Linear(50*72*22, 800) #why lol\n",
        "    self.fc2 = nn.Linear(800, 100)\n",
        "    self.fc3 = nn.Linear(100,1)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.relu4 = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(f\"initial shape: {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"shape after conv 1(1->20): {x.shape}\")\n",
        "    x = self.relu1(x)\n",
        "    #print(f\"shape after relu: {x.shape}\")\n",
        "    x = self.maxpool1(x)\n",
        "    #print(f\"shape after maxpool: {x.shape}\")\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"shape after conv1 (20->50) {x.shape}\")\n",
        "    x = self.relu2(x)\n",
        "    #print(f\"shape after relu: {x.shape}\")\n",
        "    x = self.maxpool2(x)\n",
        "    #print(f\"shape after maxpool: {x.shape}\")\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu3(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu4(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = PecletPredictor()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "JsP0h-0sjKXx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "trainset = LandlabBatchdataset(database, files, label_query, train_filter)\n",
        "testset = LandlabBatchdataset(database, files, label_query, test_filter)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "yQLjcG9_9I7P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad(set_to_none=False)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        try:\n",
        "          loss.backward()\n",
        "        except RuntimeError:\n",
        "          print(outputs, labels)\n",
        "          print([type(o) for o in outputs], [type[l] for l in labels])\n",
        "          raise RuntimeError\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "id": "Q7Fs8VdeA7Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss"
      ],
      "metadata": {
        "id": "F4p23Oh3OsYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        loss += criterion(outputs, labels)\n",
        "print(loss/len(testloader))"
      ],
      "metadata": {
        "id": "5FGHvqZfyLTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwFJf5nby3Lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}